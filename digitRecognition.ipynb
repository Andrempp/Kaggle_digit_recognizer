{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digitRecognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8Cd370gE-liV",
        "colab_type": "code",
        "outputId": "9d64eebc-3db7-4e5f-ba52-db3608507259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GKJ7foSS_FUU",
        "colab_type": "code",
        "outputId": "fb102bfb-f7ee-4019-91ab-c480b8cd2463",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7911f344-c257-4a54-8d72-d4f59c832326\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7911f344-c257-4a54-8d72-d4f59c832326\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r6Ic8kH9BXip",
        "colab_type": "code",
        "outputId": "6a78b7a4-fdfd-4bf9-c7c8-273bb13fb895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2590            True  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      10536            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4227            True  \n",
            "imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         36           False  \n",
            "competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       2617           False  \n",
            "two-sigma-financial-news                       2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "aerial-cactus-identification                   2019-07-08 23:59:00  Playground       Knowledge        189           False  \n",
            "iwildcam-2019-fgvc6                            2019-06-07 23:59:00  Playground           Kudos         11           False  \n",
            "LANL-Earthquake-Prediction                     2019-06-03 23:59:00  Research           $50,000       2081           False  \n",
            "tmdb-box-office-prediction                     2019-05-30 23:59:00  Playground       Knowledge        530           False  \n",
            "dont-overfit-ii                                2019-05-07 23:59:00  Playground            Swag       1301           False  \n",
            "ciphertext-challenge-ii                        2019-04-25 23:59:00  Playground            Swag          5           False  \n",
            "data-science-for-good-careervillage            2019-04-23 23:59:00  Analytics          $15,000          0           False  \n",
            "gendered-pronoun-resolution                    2019-04-22 23:59:00  Research           $25,000        547           False  \n",
            "career-con-2019                                2019-04-11 23:59:00  Recruitment           Swag        993           False  \n",
            "santander-customer-transaction-prediction      2019-04-10 23:59:00  Featured           $65,000       7804           False  \n",
            "womens-machine-learning-competition-2019       2019-04-10 06:00:00  Featured           $25,000        504           False  \n",
            "mens-machine-learning-competition-2019         2019-04-09 06:00:00  Featured           $25,000        871           False  \n",
            "histopathologic-cancer-detection               2019-03-30 23:59:00  Playground       Knowledge       1116           False  \n",
            "petfinder-adoption-prediction                  2019-03-28 23:59:00  Featured           $25,000       2008           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "foEwJxK_BgMp",
        "colab_type": "code",
        "outputId": "f4a5eb1a-8e39-400b-9c85-7d97c910a799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.csv to /content\n",
            " 81% 59.0M/73.2M [00:00<00:00, 109MB/s]\n",
            "100% 73.2M/73.2M [00:00<00:00, 114MB/s]\n",
            "Downloading test.csv to /content\n",
            " 92% 45.0M/48.8M [00:00<00:00, 82.1MB/s]\n",
            "100% 48.8M/48.8M [00:00<00:00, 99.2MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 45.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Kk9NmyvBwNP",
        "colab_type": "code",
        "outputId": "7834d59e-827f-464d-e755-ac4d8fbf1de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  sample_submission.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8cZyB8iIcwcL",
        "colab_type": "code",
        "outputId": "8ba5e60a-5b2f-4f9a-f637-b1246b216dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = 'My Drive/Colab Notebooks/K_Digit_Recognizer'\n",
        "drive_full_path = '/content/drive/' + drive_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IqY3b4naGWRQ",
        "colab_type": "code",
        "outputId": "7228d00e-cd0b-47a0-866b-f2ed3ce426dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive_full_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/K_Digit_Recognizer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "oDAXv6DCCmQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvgJiZURCnjM",
        "colab_type": "code",
        "outputId": "049a132f-85bf-4503-88c6-9a9aa8b29a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "train_on_gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "w3n3oRkXOsHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CSVDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, height, width, channels,transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.channels = channels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, we use ToTensor(), so we define the numpy array like (H, W, C)\n",
        "        image_numpy = self.data.iloc[index, 1:].values.astype(np.uint8).reshape(\n",
        "            (self.height, self.width))\n",
        "        image = Image.fromarray(image_numpy.astype('uint8'))\n",
        "\n",
        "        label = int(self.data.iloc[index, 0])\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)   #transform.toTensor already /255\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QprqK4PfPaIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_transforms = {'train':transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor()\n",
        "    ]) ,\n",
        "    'val':transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "                  }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cngyPntR351Z",
        "colab_type": "code",
        "outputId": "8869bcbd-75d6-4556-d4d0-83876d683535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_ratio=0.8\n",
        "\n",
        "df = pd.read_csv('train.csv',dtype = np.float32)\n",
        "\n",
        "middle = int(df.shape[0] * train_ratio)\n",
        "print(middle)\n",
        "\n",
        "train = df.iloc[:middle]\n",
        "val = df.iloc[middle:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UBq6J4PfC5ry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = CSVDataset(train, 28, 28, 1, transform=data_transforms['train'])\n",
        "val_dataset = CSVDataset(val, 28, 28, 1, transform=data_transforms['val'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdD1MKc_QkMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "218bPO-7IjlO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNISTNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "      torch.nn.Conv2d(1, 32, 5, padding=2),\n",
        "      nn.ReLU(),\n",
        "      torch.nn.Conv2d(32, 32, 5, padding=2),\n",
        "      nn.ReLU(),\n",
        "      torch.nn.MaxPool2d(kernel_size=2)\n",
        "    ) #32,14,14\n",
        "    self.layer2 = nn.Sequential(\n",
        "      torch.nn.Conv2d(32, 64, 3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      torch.nn.Conv2d(64, 64, 3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    ) #64, 7, 7\n",
        "    self.fc1 = torch.nn.Linear(7*7*64, 256)\n",
        "    self.fc2 = torch.nn.Linear(256, 10)\n",
        "   \n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = self.layer2(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = x.reshape(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, p=0.5)\n",
        "    out = F.softmax(self.fc2(x))\n",
        "    return out\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4PVifxlH1Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MNISTNetwork()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, verbose=True, min_lr=0.00001)\n",
        "\n",
        "load = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HYhryZC3k7RD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model(model, epochs=0, val_loss=-1):\n",
        "  checkpoint = {'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), \n",
        "              'epochs': epochs, 'val_loss': val_loss}\n",
        "  torch.save(checkpoint, drive_full_path + '/checkpoint.pt')\n",
        "  print(\"Model Saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RF8vYx-ourM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_model(checkpoint):    \n",
        "    model = MNISTNetwork()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    val_loss = checkpoint['val_loss']\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    \n",
        "    return model, optimizer, val_loss\n",
        "\n",
        "checkpoint = torch.load(drive_full_path + '/checkpoint.pt')\n",
        "\n",
        "model, optimizer, val_loss = load_model(checkpoint)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, verbose=True, min_lr=0.00001)\n",
        "\n",
        "load = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBW0_JFTbcIR",
        "colab_type": "code",
        "outputId": "1862ac0f-8b53-476c-dd8b-e7f5137981d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4947
        }
      },
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 40\n",
        "\n",
        "early_stop = 15\n",
        "es_counter = 0\n",
        "\n",
        "valid_loss_min = val_loss if load else np.Inf # track change in validation loss\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy=0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for batch_number, (data, target) in enumerate(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "        if batch_number%50 == 0:\n",
        "            print(\"batch number: {}\".format(batch_number))\n",
        "        \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        _,pred=torch.max(output,1)\n",
        "        accuracy += torch.sum(pred==target.data)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(val_loader.dataset)\n",
        "    accuracy = accuracy.double()/len(val_loader.dataset)\n",
        "    \n",
        "    scheduler.step(val_loss)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\\tAccuracy: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss,accuracy))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min, valid_loss))\n",
        "        save_model(model, epoch, valid_loss)\n",
        "        valid_loss_min = valid_loss\n",
        "        es_counter = 0\n",
        "    else:\n",
        "        es_counter+=1\n",
        "    \n",
        "    if es_counter >= early_stop:\n",
        "        print(\"\\n\\nEarly stop, no improvements in {} epochs\".format(early_stop))\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 1 \tTraining Loss: 1.506401 \tValidation Loss: 1.497586\tAccuracy: 0.963810\n",
            "Validation loss decreased (1.518152 --> 1.497586).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 2 \tTraining Loss: 1.505818 \tValidation Loss: 1.494717\tAccuracy: 0.966667\n",
            "Validation loss decreased (1.497586 --> 1.494717).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 3 \tTraining Loss: 1.499759 \tValidation Loss: 1.505020\tAccuracy: 0.955952\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch     4: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Epoch: 4 \tTraining Loss: 1.500940 \tValidation Loss: 1.493852\tAccuracy: 0.967143\n",
            "Validation loss decreased (1.494717 --> 1.493852).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 5 \tTraining Loss: 1.493378 \tValidation Loss: 1.488623\tAccuracy: 0.972500\n",
            "Validation loss decreased (1.493852 --> 1.488623).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 6 \tTraining Loss: 1.488166 \tValidation Loss: 1.483454\tAccuracy: 0.977857\n",
            "Validation loss decreased (1.488623 --> 1.483454).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 7 \tTraining Loss: 1.488838 \tValidation Loss: 1.485922\tAccuracy: 0.975000\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch     8: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Epoch: 8 \tTraining Loss: 1.487300 \tValidation Loss: 1.485884\tAccuracy: 0.975119\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 9 \tTraining Loss: 1.484639 \tValidation Loss: 1.483509\tAccuracy: 0.977619\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 10 \tTraining Loss: 1.482801 \tValidation Loss: 1.482146\tAccuracy: 0.978690\n",
            "Validation loss decreased (1.483454 --> 1.482146).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 11 \tTraining Loss: 1.482142 \tValidation Loss: 1.480232\tAccuracy: 0.980833\n",
            "Validation loss decreased (1.482146 --> 1.480232).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch    12: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Epoch: 12 \tTraining Loss: 1.482636 \tValidation Loss: 1.480540\tAccuracy: 0.980595\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 13 \tTraining Loss: 1.481913 \tValidation Loss: 1.481510\tAccuracy: 0.979762\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 14 \tTraining Loss: 1.480922 \tValidation Loss: 1.482409\tAccuracy: 0.978690\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 15 \tTraining Loss: 1.480133 \tValidation Loss: 1.480809\tAccuracy: 0.980238\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch    16: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Epoch: 16 \tTraining Loss: 1.479821 \tValidation Loss: 1.480767\tAccuracy: 0.980000\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 17 \tTraining Loss: 1.480478 \tValidation Loss: 1.478843\tAccuracy: 0.981905\n",
            "Validation loss decreased (1.480232 --> 1.478843).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 18 \tTraining Loss: 1.478812 \tValidation Loss: 1.480989\tAccuracy: 0.980119\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 19 \tTraining Loss: 1.478952 \tValidation Loss: 1.479188\tAccuracy: 0.981548\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch    20: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Epoch: 20 \tTraining Loss: 1.479651 \tValidation Loss: 1.479609\tAccuracy: 0.981548\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 21 \tTraining Loss: 1.479524 \tValidation Loss: 1.478863\tAccuracy: 0.982262\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 22 \tTraining Loss: 1.479695 \tValidation Loss: 1.479273\tAccuracy: 0.982024\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 23 \tTraining Loss: 1.478617 \tValidation Loss: 1.479373\tAccuracy: 0.982024\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch    24: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Epoch: 24 \tTraining Loss: 1.479258 \tValidation Loss: 1.480237\tAccuracy: 0.980833\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 25 \tTraining Loss: 1.478907 \tValidation Loss: 1.480144\tAccuracy: 0.980595\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 26 \tTraining Loss: 1.478408 \tValidation Loss: 1.480075\tAccuracy: 0.980833\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 27 \tTraining Loss: 1.478786 \tValidation Loss: 1.478538\tAccuracy: 0.982500\n",
            "Validation loss decreased (1.478843 --> 1.478538).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch    28: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 28 \tTraining Loss: 1.478378 \tValidation Loss: 1.479838\tAccuracy: 0.981310\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 29 \tTraining Loss: 1.478568 \tValidation Loss: 1.478116\tAccuracy: 0.983095\n",
            "Validation loss decreased (1.478538 --> 1.478116).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 30 \tTraining Loss: 1.478562 \tValidation Loss: 1.478328\tAccuracy: 0.982976\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 31 \tTraining Loss: 1.478968 \tValidation Loss: 1.478690\tAccuracy: 0.982262\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 32 \tTraining Loss: 1.478559 \tValidation Loss: 1.479092\tAccuracy: 0.981786\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 33 \tTraining Loss: 1.478696 \tValidation Loss: 1.476524\tAccuracy: 0.984524\n",
            "Validation loss decreased (1.478116 --> 1.476524).  Saving model ...\n",
            "Model Saved\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 34 \tTraining Loss: 1.478070 \tValidation Loss: 1.477696\tAccuracy: 0.983571\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 35 \tTraining Loss: 1.477632 \tValidation Loss: 1.479693\tAccuracy: 0.981429\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 36 \tTraining Loss: 1.478787 \tValidation Loss: 1.477853\tAccuracy: 0.983214\n",
            "batch number: 0\n",
            "batch number: 50\n",
            "batch number: 100\n",
            "batch number: 150\n",
            "batch number: 200\n",
            "batch number: 250\n",
            "Epoch: 37 \tTraining Loss: 1.478172 \tValidation Loss: 1.479188\tAccuracy: 0.981786\n",
            "batch number: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MzhqMTgMFG0W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CSVDatasetTest(Dataset):\n",
        "    \n",
        "    def __init__(self, data, height, width):\n",
        "        self.data = data\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.transform = transforms.ToTensor()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, we use ToTensor(), so we define the numpy array like (H, W, C)\n",
        "        image_numpy = self.data.iloc[index].values.astype(np.uint8).reshape(\n",
        "            (self.height, self.width))\n",
        "        \n",
        "        image = self.transform(image_numpy)   #transform.toTensor already /255\n",
        "            \n",
        "        return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwsRZJP5U0KF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test.csv',dtype = np.float32)\n",
        "\n",
        "test_dataset = CSVDatasetTest(df, 28, 28)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPh132C5ENUq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame(columns = ['ImageId', 'Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_tlJlWpA9g4",
        "colab_type": "code",
        "outputId": "565d14f0-2ec9-496d-e000-96e661693960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "image_id = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    image_id+=1\n",
        "    output = model(data)\n",
        "    _,pred=torch.max(output,1)\n",
        "    \n",
        "    #row = {'ImageId' : image_id, 'Label' : pred}\n",
        "    serie = pd.Series([image_id, int(pred)],index=predictions.columns)\n",
        "    predictions = predictions.append(serie, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XGkojRE0NBuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}